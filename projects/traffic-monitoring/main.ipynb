{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import typing as t\n",
    "import pathlib as pb\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vistraff as vt\n",
    "from vistraff.alg import VehicleOccupancy\n",
    "from vistraff.data import CarTrafficDataset, CarTrafficVideo, CarTrafficTaskTwoDataset, CarTrafficTaskThreeDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ROOT: pb.Path = pb.Path('.')\n",
    "PATH_DATA: pb.Path = PATH_ROOT / 'data' / 'train'\n",
    "PATH_ASSETS: pb.Path = PATH_ROOT / 'assets'\n",
    "PATH_MASKS: pb.Path = PATH_ASSETS / 'masks'\n",
    "PATH_MODELS: pb.Path = PATH_ASSETS / 'models'\n",
    "SEED: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.default_rng(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CarTrafficDataset(PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i, frame in enumerate(dataset.context[context]):\n",
    "        if (context_dir / f'frame_{i}.jpg').exists():\n",
    "            continue\n",
    "        cv.imwrite(str(context_dir / f'frame_{i}.jpg'), frame['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m context_dir \u001b[39m=\u001b[39m pb\u001b[39m.\u001b[39mPath(PATH_DATA \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcontext_videos_frames\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcontext\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m02\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m context_dir\u001b[39m.\u001b[39mmkdir(exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m i, frame \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset\u001b[39m.\u001b[39mcontext[context]):\n\u001b[1;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m (context_dir \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mexists():\n\u001b[1;32m      6\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/git/ub-g12-compvis/projects/traffic-monitoring/vistraff/data.py:120\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mGenerator[CarTrafficContextDict, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m]:\n\u001b[1;32m    119\u001b[0m     entry: pd\u001b[39m.\u001b[39mSeries \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlookup\u001b[39m.\u001b[39miloc[index]\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mreturn\u001b[39;00m ({ \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mframe, \u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m: entry[\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m] } \u001b[39mfor\u001b[39;00m frame \u001b[39min\u001b[39;00m CarTrafficVideo(entry[\u001b[39m'\u001b[39m\u001b[39mvideo_path\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[0;32m~/Projects/git/ub-g12-compvis/projects/traffic-monitoring/vistraff/data.py:59\u001b[0m, in \u001b[0;36mCarTrafficVideo.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mVideo at path: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m could not be opened!\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath))\n\u001b[1;32m     58\u001b[0m \u001b[39mwhile\u001b[39;00m video\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m---> 59\u001b[0m     has_frame, frame \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_frame:\n\u001b[1;32m     62\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for context in range(15):\n",
    "    context_dir = pb.Path(PATH_DATA / 'context_videos_frames' / f'{context + 1:02}')\n",
    "    context_dir.mkdir(exist_ok=True, parents=True)\n",
    "    for i, frame in enumerate(dataset.context[context]):\n",
    "        if (context_dir / f'frame_{i}.jpg').exists():\n",
    "            continue\n",
    "        cv.imwrite(str(context_dir / f'frame_{i}.jpg'), frame['image'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, s = 'name'):\n",
    "    cv.imshow(s, img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyWindow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m image \u001b[39m=\u001b[39m frame[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[39m# Apply morphological operations\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m fgmask: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m bgs\u001b[39m.\u001b[39;49mapply(frame[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     11\u001b[0m _, fgmask \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mthreshold(fgmask, \u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, cv\u001b[39m.\u001b[39mTHRESH_BINARY)\n\u001b[1;32m     13\u001b[0m kernel \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mgetStructuringElement(cv\u001b[39m.\u001b[39mMORPH_CROSS, ksize\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bgs: cv.BackgroundSubtractor = cv.createBackgroundSubtractorKNN(detectShadows=False)\n",
    "vo = VehicleOccupancy(masks_path=PATH_MASKS)\n",
    "\n",
    "for i, frame in enumerate(dataset.context[3]):\n",
    "    # Read and smooth image\n",
    "    image = frame['image']\n",
    "\n",
    "\n",
    "    # Apply morphological operations\n",
    "    fgmask: np.ndarray = bgs.apply(frame['image'], None)\n",
    "    _, fgmask = cv.threshold(fgmask, 0, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_CROSS, ksize=(3, 3))\n",
    "    fgmask = cv.erode(fgmask, kernel, iterations=1)\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_CROSS, ksize=(5, 5))\n",
    "    fgmask = cv.erode(fgmask, kernel, iterations=2)\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, ksize=(3, 3))\n",
    "    fgmask = cv.dilate(fgmask, kernel, iterations=3)\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, ksize=(5, 5))\n",
    "    fgmask = cv.dilate(fgmask, kernel, iterations=2)\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, ksize=(7, 7))\n",
    "    fgmask = cv.dilate(fgmask, kernel, iterations=1)\n",
    "\n",
    "    # Find the contours to do object detection\n",
    "    contours, _ = cv.findContours(fgmask, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Show FPS counter\n",
    "    fg_image = cv.bitwise_and(image, image, mask=fgmask)\n",
    "    image: np.ndarray = cv.putText(image, f'Frame: {i + 1}', (10, 30), cv.FONT_ITALIC, 1, (255, 255, 255), 2, cv.LINE_AA)\n",
    "    frameCopy = image.copy()\n",
    "\n",
    "    # Draw BBOXes\n",
    "    for cnt in contours:\n",
    "        if 2_000 < cv.contourArea(cnt):\n",
    "            x, y, width, height = cv.boundingRect(cnt)\n",
    "            cv.rectangle(frameCopy, (x, y), (x + width, y + height), (0, 0, 255), 2)\n",
    "            cv.putText(frameCopy, 'Car Detected', (x , y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.3, (0,255,0), 1, cv.LINE_AA)\n",
    "\n",
    "    # Obtain mask for the predefined lanes\n",
    "    # fgmask_lane: np.ndarray = (fgmask != 0) * (vo.lanes_mask != 0)\n",
    "    # fgmask_lane = np.tile(fgmask_lane[..., np.newaxis], (1, 1, 3))\n",
    "\n",
    "    # Draw\n",
    "    cv.imshow('frame', image)\n",
    "    cv.imshow('copy', frameCopy)\n",
    "    cv.imshow('foreground', fg_image)\n",
    "    cv.imshow('bg', bgs.getBackgroundImage())\n",
    "    cv.waitKey(int((1 / frame['fps']) * 500))\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ub-g12-compvis-Q2g9c7O9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
