{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c090ce91",
   "metadata": {},
   "source": [
    "## Grabcat - Foreground/background segmentation of cats in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e287c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.io\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a16f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(image_1, image_2=None, image_3=None, name_1='image_1', name_2='image_2', name_3='image_3', time_out=0):\n",
    "    \"\"\"\n",
    "    Show images received as parameters.\n",
    "    \"\"\"\n",
    "    cv.imshow(name_1, image_1)\n",
    "    if image_2 is not None:\n",
    "        cv.imshow(name_2, image_2)\n",
    "    if image_3 is not None:\n",
    "        cv.imshow(name_3, image_3)\n",
    "    cv.waitKey(time_out)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be250e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(result, gt):\n",
    "    \"\"\"\n",
    "    result : segmentation obtained\n",
    "    gt: ground-truth segmentation\n",
    "    returns precision and recall\n",
    "    \"\"\"\n",
    "    result_converted=np.asarray(result)\n",
    "    print(result_converted)\n",
    "    result_converted[result_converted<200]=0\n",
    "    result_converted[result_converted>200]=1\n",
    "    result_converted=result_converted.flatten()\n",
    "    gt_converted=np.asarray(gt)\n",
    "    gt_converted[gt_converted<200]=0\n",
    "    gt_converted[gt_converted>200]=1\n",
    "    gt_converted=gt_converted.flatten()\n",
    "    return precision_score(gt_converted,result_converted),recall_score(gt_converted,result_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945916a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regions(image):\n",
    "    \"\"\"\n",
    "    image: image for segmentation\n",
    "    -select the ROI\n",
    "    -create list with background pixels\n",
    "    -create list with foreground pixels\n",
    "    returns the coordinates of region of interest, cropped_image, background and foreground pixels\n",
    "    \"\"\"\n",
    "    r = cv.selectROI(\"select the area\", image)\n",
    "    cropped_image = image[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    "    print(cropped_image.shape)\n",
    "    show_images(cropped_image)\n",
    "    background=[]\n",
    "    #left\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(0, r[0]):\n",
    "            background.append(image[i, j, :])\n",
    "    #right\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(r[0] + r[2], image.shape[1]):\n",
    "            background.append(image[i, j, :])\n",
    "    #up\n",
    "    for i in range(r[1]):\n",
    "        for j in range(r[0], r[0] + r[2]):\n",
    "            background.append(image[i, j, :])\n",
    "    #down\n",
    "    for i in range(r[1] + r[3], image.shape[0]):\n",
    "        for j in range(r[0], r[0] + r[2]):\n",
    "            background.append(image[i, j, :])\n",
    "    b=np.array(background)\n",
    "    fb=cropped_image.reshape((-1, 3))\n",
    "    return r,b,fb,cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe4902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmean_centroids(data, k):\n",
    "    \"\"\"\n",
    "    data: data to be clustered\n",
    "    k: number of clusters\n",
    "    returns the center of clusters\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(init=\"random\", n_clusters=k, n_init=10, max_iter=300, random_state=42)\n",
    "    kmeans.fit(np.float64(data))\n",
    "    return kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "257e4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(cropped_image,iterations,centroids_b,centroids_f,b_orig,fb_orig,img_name):\n",
    "    \"\"\"\n",
    "    cropped_image: region to be segmented\n",
    "    iterations: number of iterations\n",
    "    centroids_b: number of centroids for background\n",
    "    centroids_f: number of centroids for foreground\n",
    "    b_orig: original pixels for background\n",
    "    fb_orig: original pixels from foreground and background region\n",
    "    img_name: image name for segmented image\n",
    "    -cluster background pixels\n",
    "    -cluster pixels from foreground and background region\n",
    "    -compute euclidean distance between pixels from cropped image and cluster centers\n",
    "    -assign pixels to background if minimum distance is found between a cluster from backgrpund\n",
    "    returns the segmented image\n",
    "    \"\"\"\n",
    "    b=b_orig.copy()\n",
    "    fb=fb_orig.copy()\n",
    "    for cnt in range(iterations):\n",
    "        kmeans_b=get_kmean_centroids(b,centroids_b)\n",
    "        kmeans_fb=get_kmean_centroids(fb,centroids_f)\n",
    "        img_mask=np.zeros((cropped_image.shape[0],cropped_image.shape[1]))\n",
    "        img_mask.fill(255)\n",
    "        b=b_orig.copy()\n",
    "        fb=fb_orig.copy()\n",
    "        for i in range(cropped_image.shape[0]):\n",
    "            for j in range(cropped_image.shape[1]):\n",
    "                distances_b  = []\n",
    "                distances_fb = []\n",
    "\n",
    "                for c in kmeans_b:\n",
    "                    distances_b.append(math.dist(cropped_image[i, j, :], c))\n",
    "                for c in kmeans_fb:\n",
    "                    distances_fb.append(math.dist(cropped_image[i, j, :], c))\n",
    "                min_b  = min(distances_b)\n",
    "                min_fb = min(distances_fb)\n",
    "\n",
    "                if min_b < min_fb:\n",
    "                    b = np.append(b, [cropped_image[i, j, :]], axis=0)\n",
    "                    fb = np.delete(fb, np.where(fb==[cropped_image[i,j,:]])[0][0], axis=0)\n",
    "                    img_mask[i, j] = 0\n",
    "\n",
    "        #show_images(img_mask)\n",
    "        cv.imwrite(\"segmentations/\"+img_name+'_'+str(cnt)+'.jpg', img_mask)\n",
    "    return img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f10237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/invokariman/.cache/pypoetry/virtualenvs/ub-g12-compvis-Cpc6amjP-py3.10/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 3)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/highgui/src/window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m img_name\u001b[39m=\u001b[39mimage_path\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m image \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mimages/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mimage_path)\n\u001b[0;32m----> 6\u001b[0m r,b_orig,fb_orig,cropped_image\u001b[39m=\u001b[39mget_regions(image)\n\u001b[1;32m      7\u001b[0m \u001b[39m# mask=segment_image(cropped_image,5,10,7,b_orig,fb_orig,img_name)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# full_image=np.zeros((image.shape[0],image.shape[1],1))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]]=1\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]]=full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]] * mask[:, :, np.newaxis]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(full_image)\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mget_regions\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     10\u001b[0m cropped_image \u001b[39m=\u001b[39m image[\u001b[39mint\u001b[39m(r[\u001b[39m1\u001b[39m]):\u001b[39mint\u001b[39m(r[\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39mr[\u001b[39m3\u001b[39m]), \u001b[39mint\u001b[39m(r[\u001b[39m0\u001b[39m]):\u001b[39mint\u001b[39m(r[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39mr[\u001b[39m2\u001b[39m])]\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(cropped_image\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 12\u001b[0m show_images(cropped_image)\n\u001b[1;32m     13\u001b[0m background\u001b[39m=\u001b[39m[]\n\u001b[1;32m     14\u001b[0m \u001b[39m#left\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mshow_images\u001b[0;34m(image_1, image_2, image_3, name_1, name_2, name_3, time_out)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_images\u001b[39m(image_1, image_2\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, image_3\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name_1\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimage_1\u001b[39m\u001b[39m'\u001b[39m, name_2\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimage_2\u001b[39m\u001b[39m'\u001b[39m, name_3\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimage_3\u001b[39m\u001b[39m'\u001b[39m, time_out\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    Show images received as parameters.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     cv\u001b[39m.\u001b[39;49mimshow(name_1, image_1)\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m image_2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         cv\u001b[39m.\u001b[39mimshow(name_2, image_2)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/highgui/src/window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "image_path='03.jpg'\n",
    "gt_image_path='03.png'\n",
    "gt_image=cv.imread('ground_truth/' + gt_image_path,cv.IMREAD_GRAYSCALE)\n",
    "img_name=image_path.split('.')[0]\n",
    "image = cv.imread('images/'+image_path)\n",
    "r,b_orig,fb_orig,cropped_image=get_regions(image)\n",
    "# mask=segment_image(cropped_image,5,10,7,b_orig,fb_orig,img_name)\n",
    "# full_image=np.zeros((image.shape[0],image.shape[1],1))\n",
    "# full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]]=1\n",
    "# full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]]=full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]] * mask[:, :, np.newaxis]\n",
    "\n",
    "print(full_image)\n",
    "# show_images(full_image)\n",
    "# cv.imwrite(\"segmentations/\"+img_name+'_classic'+'.jpg', full_image)\n",
    "# print(measure_performance(full_image.copy(),gt_image.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0ece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m gt_image_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m02.png\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     15\u001b[0m gt_image\u001b[39m=\u001b[39mcv\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mground_truth/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mgt_image_path,cv\u001b[39m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m---> 16\u001b[0m mask \u001b[39m=\u001b[39m run_grabcut(img)\n\u001b[1;32m     17\u001b[0m show_images(image_1\u001b[39m=\u001b[39mmask, name_1\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimg_grabcut\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[1;32m     18\u001b[0m cv\u001b[39m.\u001b[39mimwrite(\u001b[39m\"\u001b[39m\u001b[39msegmentations/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m img_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_grabcut\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m, mask)\n",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m, in \u001b[0;36mrun_grabcut\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      6\u001b[0m rect \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mselectROI(img)\n\u001b[1;32m      7\u001b[0m cv\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m----> 8\u001b[0m cv\u001b[39m.\u001b[39;49mgrabCut(img, mask, rect, bgdModel, fgdModel, \u001b[39m5\u001b[39;49m, cv\u001b[39m.\u001b[39;49mGC_INIT_WITH_MASK)\n\u001b[1;32m     10\u001b[0m mask2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere((mask \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m|\u001b[39m(mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m),\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m mask2\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n"
     ]
    }
   ],
   "source": [
    "# https://www.docs.opencv.org/master/d8/d83/tutorial_py_grabcut.html\n",
    "def run_grabcut(img):\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1,65), np.float64)\n",
    "    fgdModel = np.zeros((1,65), np.float64)\n",
    "    rect = cv.selectROI(img)\n",
    "    cv.destroyAllWindows()\n",
    "    cv.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv.GC_INIT_WITH_RECT)\n",
    "    \n",
    "    mask2 = np.where((mask == 2)|(mask == 0),0,255).astype('uint8')\n",
    "    return mask2\n",
    "    \n",
    "img = cv.imread('images/02.jpg')\n",
    "gt_image_path='02.png'\n",
    "gt_image=cv.imread('ground_truth/'+gt_image_path,cv.IMREAD_GRAYSCALE)\n",
    "mask = run_grabcut(img)\n",
    "show_images(image_1=mask, name_1='img_grabcut') \n",
    "cv.imwrite(\"segmentations/\" + img_name + '_grabcut'+'.jpg', mask)\n",
    "print(measure_performance(mask,gt_image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
